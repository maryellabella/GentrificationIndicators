{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Property as an Indicator for Gentrification\"\n",
        "author: Sarah Kim (skimmy28) & Maryell Abella (maryellabella)\n",
        "format: html\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### Research Question & Background\n",
        "\n",
        "As we both had a strong interest in housing, having taken a course in housing policy at Harris, it naturally ushered us into choosing a topic related to housing. Based on our understanding that the south and west side of Chicago are more likely to be burdened with displacement due to gentrification, we sought to find indicators across multiple years that may signal these issues. Additionally, before 2018, the Cook County Assessor’s Office was plagued with corruption issues and scandals that affected lower-income communities. Lacking transparency, the new assessor installed a data team to incorporate mass appraisal techniques to produce property values and share that data with the public. For our final project, we focused on property indicators suggesting a neighborhood is experiencing gentrification. \n",
        "\n",
        "#### Data Aggregation & Cleaning\n",
        "\n",
        "Many factors play a significant role in gentrification, such as rising housing costs or increased accommodations such as parks and commercial buildings. However, the biggest limitation was finding usable data. We utilized Cook County’s Assessor’s open data portal where we found housing-related datasets. However, we realized these datasets were large with over 33 million rows spanning several years. As a result, we realized we needed to cut certain aspects to make the datasets downloadable and usable in Python. Another difficulty, we encountered was that when we did find these datasets, a lot of the data was found to be missing. For example, one dataset from the Assessor’s portal had parcel accommodations with columns such as the distance from the nearest school, hospital, or park. However, upon downloading the data and cleaning the data in VS Code, we found that the columns only had 20% of the data. \n",
        "\n",
        "We decided to settle on using these years: 2000, 2006, 2012, 2018, and 2023 because the Assessor’s office reassesses ⅓ of the properties every 3 years, processed in thirds by the triads of the City of Chicago, northern suburbs, and southern suburbs. Additionally, we settled on three indicators: assessed value, number of foreclosures (within a half mile in 5 years), and parcel sales. Assessed value relates to the land and building total assessed values for all Cook County parcels. Foreclosures notes when a mortgaged property is repossessed by a bank since the mortgagor fails to keep up their payments. Lastly, parcel sales provides information on how much a land and building were sold for. \n",
        "\n",
        "We used the Cook County Assessor shapefile to map out the the CSV information stored for each topic geographically by their unique parcel pin. However, the shapefile does not explicitly show Chicago boundaries or neighborhoods. We clipped, merged, and converted the values from each topic’s CSVs into an average with the boundaries of the City of Chicago through the City’s shapefile of their neighborhoods. \n",
        "\n",
        "#### Shiny Application & Graphs\n",
        "\n",
        "We decided to put all our charts and graphs into our Shiny app in order to visually show changes through time. The dashboard includes three tabs: Assessed Value, Foreclosures, and Parcel Sales. All the tabs have the same format with 3 cards and sidebar that includes two drop down menus that toggle for years for the associated table, a toggle for neighborhood, and another to toggle the year for the choropleth. \n",
        "\n",
        "![Shiny Dashboard](pictures.png)\n",
        "\n",
        "The first shiny card shows the top ten neighborhoods with the highest difference.\n",
        "In the example, we show the difference between the assessed value for 2000 and 2023. However, we can toggle between different years showcasing 2012 vs 2023 (among the six chosen years we have). The same is true for Foreclosures and Parcel Sales. The next card graph is our Altair line graph. It can toggle to a specific neighborhood and show a timescape of the values (same for foreclosures and parcel sales) within a neighborhood. The dotted line is the average of all the neighborhoods in Chicago. The third card graph is our choropleth which shows a heatmap variation of the selected tab topic by year. It uses a tooltip to hover over and show the neighborhood and its corresponding value. \n",
        "\n",
        "#### Findings & Data Analysis \n",
        "\n",
        "For assessed value, we see that Greektown had the highest increase between 2000 and 2023.\n",
        "The choropleth from the assessed values seemed more uniform throughout the city in 2000, though starting in 2018 it shows that the highest-valued properties are on the north side of Chicago. Auburn Gresham had the most foreclosures between 2000 and 2023. For the year 2000, there seems to be little to no foreclosures. Based on the choropleth on foreclosures in 2012 to 2023, most foreclosed properties are in the west and south side of Chicago. O’Hare has the highest value in parcel sale between 2000 and 2023. There is no clear pattern for the choropleth on parcel sales in Chicago. However, neighborhoods such as South Shore, Little Village, Archer Heights, and Humbolt Park faced streep increases in parcel sale values from 2018 (pre-pandemic) to 2023 (post-pandemic) and were included in the top ten neighborhoods of the shiny. Indicating that these neighborhoods may be facing gentrification.\n",
        "\n",
        "#### Policy Implications of Our Findings\n",
        "\n",
        "With our dashboard, one of the policy implications we use for our findings is to monitor economic displacement which would allow us to identify neighborhoods experiencing significant changes. This is key to addressing any neighborhoods feeling displacement pressures. Another policy implication is to develop equitable policies that would highlight disparities in property value increase and affordability across neighborhoods. An additional policy implication would to be increase data transparency and community engagement where findings can be shared with stakeholders to empower communities. Lastly, tax policy adjustments can be made to cater to rising property taxes that disproportionately affect long-term, lower-income residents. \n",
        "\n",
        "#### Direction for Future Work\n",
        "\n",
        "If given additional time and resources, it would be useful and insightful to plot demographic data. It would provide a bigger picture if certain minority groups or income levels are being displaced. Additionally, it would be able to show the demographic makeup of certain regions that have changed pre- and post-gentrified periods. Especially since when people think of gentrification, they think of “white yuppies” taking over neighborhoods where they add Whole Foods and artisan coffee shops. We want to use demographic data to either further prove or disprove this claim. Additionally, we would have liked to plot public spaces such as schools, parks, and hospitals. Especially if we consider the strong relationship between schools and property values where neighborhoods with higher property values tend to have access to higher-quality public education. \n"
      ],
      "id": "cac07c98"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import altair as alt"
      ],
      "id": "9f627acb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import os\n",
        "#google drive link to data: https://drive.google.com/file/d/1PKFj8sjllTELf7ygwrGi7E9DDq08Swhz/view?usp=drive_link\n",
        "path = r'/Users/maryell/Desktop/finalproject/'\n",
        "#path = r'/Users/sarahkim/Documents/Coding/'"
      ],
      "id": "b997ba49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Assessed Value Data Cleaning\n",
        "assessed_value = 'Assessed_Value.csv'\n",
        "absolute_path_av = os.path.join(path, assessed_value)\n",
        "av_df = pd.read_csv(absolute_path_av)\n",
        "print(av_df.head())"
      ],
      "id": "2ec1253f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# assessor neighborhood boundaries shapefile\n",
        "neighborhood_folder = 'Neighborhood_Boundaries'\n",
        "neighborhood_path = os.path.join(path, neighborhood_folder,\n",
        " 'geo_export_ad3b7229-3a91-4260-85b6-64676cb28962.shp')\n",
        "neighborhood_gdf = gpd.read_file(neighborhood_path)\n",
        "print(neighborhood_gdf.columns)\n",
        "print(neighborhood_gdf.crs)\n",
        "neighborhood_gdf = neighborhood_gdf[neighborhood_gdf['triad_code'] == '1']\n",
        "print(neighborhood_gdf.head())"
      ],
      "id": "bc609750",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# chicago zip code\n",
        "zip_neighborhood_folder = 'zip_neighborhood'\n",
        "zip_neighborhood_path = os.path.join(path, zip_neighborhood_folder, \n",
        "'geo_export_94c921b1-33a1-481a-9c36-7e6d40530da7.shp')\n",
        "zip_neighborhood_gdf = gpd.read_file(zip_neighborhood_path)\n",
        "print(zip_neighborhood_gdf.columns)\n",
        "print(zip_neighborhood_gdf.head())\n",
        "print(zip_neighborhood_gdf.crs)"
      ],
      "id": "da11e56c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Shapefile join\n",
        "neighborhood_gdf = gpd.sjoin(neighborhood_gdf, \n",
        "                             zip_neighborhood_gdf[['shape_area', \n",
        "                             'pri_neigh', 'sec_neigh', 'geometry']], \n",
        "                             how='left', \n",
        "                             predicate='intersects')\n",
        "\n",
        "print(neighborhood_gdf.columns)\n",
        "\n",
        "clipped_gdf = gpd.clip(neighborhood_gdf, zip_neighborhood_gdf)\n",
        "\n",
        "print(clipped_gdf[['pri_neigh', 'sec_neigh']].head())"
      ],
      "id": "0a87d3ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Data cleaning to merge \n",
        "av_df['certified_tot'] = av_df['certified_tot'].astype(str).str.replace(\n",
        "    ',', '').astype(float)\n",
        "av_df.rename(columns={'tax_year': 'year'}, inplace=True)\n",
        "\n",
        "av_df['township_code'] = av_df['neighborhood_code'].astype(str).str[:2]\n",
        "av_df['neighborhood_code_clean'] = av_df['neighborhood_code'].astype(str).str[2:]\n",
        "\n",
        "clipped_gdf['township_code'] = clipped_gdf['town_nbhd'].astype(str).str[:2]\n",
        "clipped_gdf['neighborhood_code_clean'] = clipped_gdf['town_nbhd'].astype(str).str[2:]\n",
        "\n",
        "av_df['certified_tot'] = pd.to_numeric(av_df['certified_tot'])\n",
        "\n",
        "av_merged_df = pd.merge(av_df, clipped_gdf, \n",
        "                        left_on=['township_code', 'neighborhood_code_clean'],\n",
        "                        right_on=['township_code', 'neighborhood_code_clean'],\n",
        "                        how='inner')\n",
        "\n",
        "av_aggregated = av_merged_df.groupby(['township_code', 'neighborhood_code_clean',\n",
        " 'year']).agg({'certified_tot': 'mean'}).reset_index()\n",
        "\n",
        "merged_gdf = clipped_gdf.merge(av_aggregated, \n",
        "                               left_on=['township_code', 'neighborhood_code_clean'], \n",
        "                               right_on=['township_code', 'neighborhood_code_clean'],\n",
        "                               how='left')\n",
        "\n",
        "merged_gdf['certified_tot_mean'] = merged_gdf.groupby([\n",
        "    'geometry', 'year'])['certified_tot'].transform('mean')\n",
        "\n",
        "print(merged_gdf.head())\n",
        "\n",
        "# Save as Shapefile\n",
        "shapefile_path = os.path.join(path, 'merged_gdf_shapefile')\n",
        "merged_gdf.to_file(shapefile_path, driver='ESRI Shapefile')"
      ],
      "id": "0cea4a86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Choropleth by Year\n",
        "merged_gdf_2020 = merged_gdf[merged_gdf['year'] == 2020]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5), dpi=75)\n",
        "\n",
        "merged_gdf_2020.plot(column='certified_tot_mean', ax=ax, legend=True,\n",
        "                    cmap='Blues', edgecolor='lightgray', linewidth=0.5)\n",
        "\n",
        "ax.set_title('Average Assessed Value by Neighborhood 2020)')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "id": "ed506e1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Aggregate by Year\n",
        "agg_merged = merged_gdf.groupby('year', as_index=False)['certified_tot_mean'].mean()\n",
        "\n",
        "agg_merged['certified_tot_mean_millions'] = agg_merged['certified_tot_mean']"
      ],
      "id": "8f287dd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Altair Line Graph\n",
        "line_chart = alt.Chart(agg_merged).mark_line().encode(\n",
        "    x=alt.X('year:O', title='Year'), \n",
        "    y=alt.Y('certified_tot_mean_millions:Q', \n",
        "            title='Certified Total (in millions)',\n",
        "            axis=alt.Axis(format='.1f')), \n",
        "    tooltip=[alt.Tooltip('year:O', title='Year'),\n",
        "            alt.Tooltip('certified_tot_mean_millions:Q', format='.2f', \n",
        "            title='Certified Total')],\n",
        ").properties(\n",
        "    title=\"Average Certified Total by Year\",\n",
        "    width=600,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "line_chart"
      ],
      "id": "8f3d3884",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Foreclosure \n",
        "assessed_value = 'Assessed_Value.csv'\n",
        "absolute_path_av = os.path.join(path, assessed_value)\n",
        "av_df = pd.read_csv(absolute_path_av)\n",
        "print(av_df.head())"
      ],
      "id": "c8eff7bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Foreclosure File\n",
        "parcel_proximity_fc = 'Assessor_-_Parcel_Proximity_20241121(foreclosure).csv'\n",
        "absolute_path_fc = os.path.join(path, parcel_proximity_fc)\n",
        "fc_df = pd.read_csv(absolute_path_fc)\n",
        "print(fc_df.head())"
      ],
      "id": "2b43952b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#assessor neighborhood boundaries shapefile\n",
        "neighborhood_folder = 'Neighborhood_Boundaries'\n",
        "neighborhood_path = os.path.join(path, neighborhood_folder,\n",
        " 'geo_export_ad3b7229-3a91-4260-85b6-64676cb28962.shp')\n",
        "neighborhood_gdf = gpd.read_file(neighborhood_path)\n",
        "neighborhood_gdf = neighborhood_gdf[neighborhood_gdf['triad_code'] == '1']\n",
        "print(neighborhood_gdf.columns)\n",
        "print(neighborhood_gdf.head())"
      ],
      "id": "94ae3e69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#chicago zip code\n",
        "zip_neighborhood_folder = 'zip_neighborhood'\n",
        "zip_neighborhood_path = os.path.join(path, zip_neighborhood_folder, \n",
        "'geo_export_94c921b1-33a1-481a-9c36-7e6d40530da7.shp')\n",
        "zip_neighborhood_gdf = gpd.read_file(zip_neighborhood_path)\n",
        "print(zip_neighborhood_gdf.columns)\n",
        "print(zip_neighborhood_gdf.head())"
      ],
      "id": "d2ca803f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Shapefile join\n",
        "neighborhood_gdf = gpd.sjoin(neighborhood_gdf, \n",
        "                             zip_neighborhood_gdf[['shape_area',\n",
        "                              'pri_neigh', 'sec_neigh', 'geometry']], \n",
        "                             how='left', \n",
        "                             predicate='intersects')\n",
        "\n",
        "print(neighborhood_gdf.columns)\n",
        "\n",
        "clipped_gdf = gpd.clip(neighborhood_gdf, zip_neighborhood_gdf)\n",
        "\n",
        "print(clipped_gdf[['pri_neigh', 'sec_neigh']].head())"
      ],
      "id": "8bff8919",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#Foreclosure - Parcel Foreclosure and Shapefile (fc_df & neighborhood_gdf)\n",
        "print(clipped_gdf.columns)\n",
        "print(av_df.columns)\n",
        "print(av_df.head())\n",
        "print(fc_df.columns)\n",
        "print(fc_df.head())"
      ],
      "id": "556995f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Data Cleaning for merge\n",
        "av_df['township_code'] = av_df['neighborhood_code'].astype(str).str[:2]\n",
        "av_df['neighborhood_code_clean'] = av_df['neighborhood_code'].astype(str).str[2:]\n",
        "\n",
        "clipped_gdf['township_code'] = clipped_gdf['town_nbhd'].astype(str).str[:2]\n",
        "clipped_gdf['neighborhood_code_clean'] = clipped_gdf['town_nbhd'].astype(str).str[2:]"
      ],
      "id": "fe64acfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Data cleaning for merge\n",
        "av_df['certified_tot'] = av_df['certified_tot'].astype(str).str.replace(\n",
        "    ',', '').astype(float)\n",
        "av_df.rename(columns={'tax_year': 'year'}, inplace=True)  \n",
        "fc_df.rename(columns={'pin10': 'pin'}, inplace=True) \n",
        "av_df['pin'] = av_df['pin'].astype(str).str[:10].str.strip()\n",
        "fc_df['pin'] = fc_df['pin'].astype(str).str.strip() \n",
        "fc_df = fc_df.dropna(subset=['year'])\n",
        "\n",
        "fc_merged_df = pd.merge(av_df, fc_df, on=['pin', 'year'], how='left', indicator=True)\n",
        "\n",
        "match_count = fc_merged_df['_merge'].value_counts()\n",
        "print(match_count)"
      ],
      "id": "464f2d1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Remove NA Values\n",
        "fc_merged_df.dropna(subset=['num_foreclosure_data_year',\n",
        " 'num_foreclosure_in_half_mile_past_5_years'], inplace=True)\n",
        "\n",
        "print(fc_merged_df.head())"
      ],
      "id": "c950b26a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Merging files and grouping by similar columns\n",
        "fc_merged_df.columns = fc_merged_df.columns.str.strip()\n",
        "\n",
        "fc_merged_df = pd.merge(fc_merged_df, clipped_gdf, \n",
        "                        left_on=['township_code', 'neighborhood_code_clean'],\n",
        "                        right_on=['township_code', 'neighborhood_code_clean'],\n",
        "                        how='inner')\n",
        "\n",
        "fc_aggregated = fc_merged_df.groupby(['township_code', 'neighborhood_code_clean',\n",
        " 'year']).agg(\n",
        "    {'num_foreclosure_in_half_mile_past_5_years': 'mean'}).reset_index()\n",
        "\n",
        "fc_aggregated = fc_aggregated.dropna(subset=['year'])\n",
        "print(fc_aggregated.head())"
      ],
      "id": "a1ac7517",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Merging data to Shapefile\n",
        "fc_merged_gdf = clipped_gdf.merge(fc_aggregated, \n",
        "                                   left_on=['township_code', \n",
        "                                   'neighborhood_code_clean'], \n",
        "                                   right_on=['township_code', \n",
        "                                   'neighborhood_code_clean'],\n",
        "                                   how='left')\n",
        "\n",
        "print(fc_merged_gdf.head())"
      ],
      "id": "3bdbd207",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Foreclosure mean by Neighborhood\n",
        "fc_merged_gdf['num_foreclosure_in_half_mile_past_5_years_mean'\n",
        "] = fc_merged_gdf.groupby(['geometry', 'year'])[\n",
        "    'num_foreclosure_in_half_mile_past_5_years'].transform('mean')\n",
        "\n",
        "print(fc_merged_gdf.head())\n",
        "\n",
        "# Save as Shapefile\n",
        "shapefile_path = os.path.join(path, 'fc_gdf_shapefile')\n",
        "fc_merged_gdf.to_file(shapefile_path, driver='ESRI Shapefile')"
      ],
      "id": "5fac9358",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Choropleth by year\n",
        "fc_merged_gdf_2000 = fc_merged_gdf[fc_merged_gdf['year'] == 2000]\n",
        "\n",
        "fc_merged_gdf_2000 = fc_merged_gdf_2000.to_crs(epsg=5070)  \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5), dpi=75)\n",
        "\n",
        "fc_merged_gdf_2000.plot(column='num_foreclosure_in_half_mile_past_5_years_mean', \n",
        "                        ax=ax, legend=True,\n",
        "                        cmap='Blues', \n",
        "                        edgecolor='lightgray', linewidth=0.5)\n",
        "\n",
        "ax.set_title('Average Foreclosures in 2000 (Half Mile, Past 5 Years) by Neighborhood')\n",
        "\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "id": "513afd7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Altair line graph\n",
        "agg_fc = fc_merged_gdf.groupby(['year']).agg(\n",
        "    {'num_foreclosure_in_half_mile_past_5_years': 'mean'}).reset_index()\n",
        "\n",
        "line_chart = alt.Chart(agg_fc).mark_line().encode(\n",
        "    x=alt.X('year:O', title='Year'),\n",
        "    y=alt.Y('num_foreclosure_in_half_mile_past_5_years:Q', \n",
        "            title='Average Foreclosures in Half Mile (Past 5 Years)',\n",
        "            axis=alt.Axis(format='.1f')),\n",
        "    tooltip=[alt.Tooltip('year:O', title='Year'),\n",
        "             alt.Tooltip('num_foreclosure_in_half_mile_past_5_years:Q', \n",
        "             format='.2f', title='Average Foreclosures')]\n",
        ").properties(\n",
        "    title=\"Average Foreclosures Over Time\",\n",
        "    width=300,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "line_chart"
      ],
      "id": "ba1ffcbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Parcel Sales\n",
        "assessed_value = 'Assessed_Value.csv'\n",
        "absolute_path_av = os.path.join(path, assessed_value)\n",
        "av_df = pd.read_csv(absolute_path_av)\n",
        "print(av_df.head())\n",
        "\n",
        "parcel_sale = 'Assessor_-_Parcel_Sales_20241121(00-23).csv'\n",
        "absolute_path_ps = os.path.join(path, parcel_sale)\n",
        "ps_df = pd.read_csv(absolute_path_ps)\n",
        "print(ps_df.head())"
      ],
      "id": "490026fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Shapefiles for Assessor and Chicago Neighborhoods\n",
        "neighborhood_folder = 'Neighborhood_Boundaries'\n",
        "neighborhood_path = os.path.join(path, neighborhood_folder,\n",
        " 'geo_export_ad3b7229-3a91-4260-85b6-64676cb28962.shp')\n",
        "neighborhood_gdf = gpd.read_file(neighborhood_path)\n",
        "neighborhood_gdf = neighborhood_gdf[neighborhood_gdf['triad_code'] == '1']\n",
        "print(neighborhood_gdf.columns)\n",
        "print(neighborhood_gdf.head())\n",
        "\n",
        "zip_neighborhood_folder = 'zip_neighborhood'\n",
        "zip_neighborhood_path = os.path.join(path, zip_neighborhood_folder, \n",
        "'geo_export_94c921b1-33a1-481a-9c36-7e6d40530da7.shp')\n",
        "zip_neighborhood_gdf = gpd.read_file(zip_neighborhood_path)\n",
        "print(zip_neighborhood_gdf.columns)\n",
        "print(zip_neighborhood_gdf.head())"
      ],
      "id": "feb2a5a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Shapefile Join \n",
        "neighborhood_gdf = gpd.sjoin(neighborhood_gdf, \n",
        "                             zip_neighborhood_gdf[['shape_area', \n",
        "                             'pri_neigh', 'sec_neigh', 'geometry']], \n",
        "                             how='left', \n",
        "                             predicate='intersects')\n",
        "\n",
        "print(neighborhood_gdf.columns)\n",
        "\n",
        "clipped_gdf = gpd.clip(neighborhood_gdf, zip_neighborhood_gdf)\n",
        "\n",
        "print(clipped_gdf[['pri_neigh', 'sec_neigh']].head())"
      ],
      "id": "e960115a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Data cleaning for Merge\n",
        "av_df['certified_tot'] = av_df['certified_tot'].astype(str).str.replace(\n",
        "    ',', '').astype(float)\n",
        "av_df.rename(columns={'tax_year': 'year'}, inplace=True)  \n",
        "av_df['township_code'] = av_df['neighborhood_code'].astype(str).str[:2]\n",
        "av_df['neighborhood_code_clean'] = av_df['neighborhood_code'].astype(str).str[2:]\n",
        "av_df['pin'] = av_df['pin'].astype(str).str[:10].str.strip()\n",
        "\n",
        "ps_df['sale_price'] = ps_df['sale_price'].astype(float)\n",
        "ps_df.drop(columns=['township_code', 'neighborhood_code'], inplace=True)\n",
        "ps_df.rename(columns={'pin10': 'pin'}, inplace=True) \n",
        "ps_df['pin'] = ps_df['pin'].astype(str).str[:10].str.strip()\n",
        "\n",
        "ps_merged_df = pd.merge(av_df, ps_df, on=['pin', 'year'], how='left', indicator=True)\n",
        "\n",
        "ps_merged_df = ps_merged_df.dropna(subset=['sale_price'])\n",
        "\n",
        "ps_merged_df['sale_price'] = ps_merged_df['sale_price'].astype(float)"
      ],
      "id": "eaaaa677",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Data Cleaning for Merge\n",
        "clipped_gdf['township_code'] = clipped_gdf['town_nbhd'].astype(str).str[:2]\n",
        "clipped_gdf['neighborhood_code_clean'] = clipped_gdf['town_nbhd'].astype(str).str[2:]\n",
        "\n",
        "ps_merged_df = pd.merge(ps_merged_df, clipped_gdf, \n",
        "                        left_on=['township_code', \n",
        "                        'neighborhood_code_clean'],\n",
        "                        right_on=['township_code', \n",
        "                        'neighborhood_code_clean'],\n",
        "                        how='inner')\n",
        "\n",
        "print(ps_merged_df.head())"
      ],
      "id": "e5943555",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Aggregating for mean by Neighborhood and year\n",
        "ps_aggregated = ps_merged_df.groupby(['township_code', \n",
        "'neighborhood_code_clean', 'year']).agg(\n",
        "    {'sale_price': 'mean'}).reset_index()\n",
        "\n",
        "ps_aggregated = ps_aggregated.dropna(subset=['year'])\n",
        "\n",
        "print(ps_aggregated.head())"
      ],
      "id": "bb2e6d1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Merging data to shapefile\n",
        "ps_merged_gdf = clipped_gdf.merge(ps_aggregated, \n",
        "                                   left_on=['township_code', \n",
        "                                   'neighborhood_code_clean'], \n",
        "                                   right_on=['township_code', \n",
        "                                   'neighborhood_code_clean'],\n",
        "                                   how='left')\n",
        "\n",
        "print(ps_merged_gdf.head())"
      ],
      "id": "0fab17b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Merging for mean by geometry\n",
        "ps_merged_gdf['sale_price_mean'] = ps_merged_gdf.groupby(['geometry', \n",
        "'year'])['sale_price'].transform('mean')\n",
        "\n",
        "print(ps_merged_gdf.head())\n",
        "\n",
        "shapefile_path = os.path.join(path, 'ps_gdf_shapefile')\n",
        "ps_merged_gdf.to_file(shapefile_path, driver='ESRI Shapefile')"
      ],
      "id": "318a2809",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Choropleth\n",
        "ps_merged_gdf_2000 = ps_merged_gdf[ps_merged_gdf['year'] == 2000]\n",
        "\n",
        "ps_merged_gdf_2000 = ps_merged_gdf_2000.to_crs(epsg=5070)  \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5), dpi=75)\n",
        "\n",
        "ps_merged_gdf_2000.plot(column='sale_price_mean', ax=ax, legend=True,\n",
        "                        cmap='Blues', \n",
        "                        edgecolor='lightgray', linewidth=0.5)\n",
        "\n",
        "ax.set_title('Average Sale Price in 2000 by Neighborhood')\n",
        "\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "id": "f7d328e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Altair line graph\n",
        "ps_merged_agg = ps_merged_gdf.groupby(['year']).agg(\n",
        "    {'sale_price_mean': 'mean'}).reset_index()\n",
        "\n",
        "line_chart = alt.Chart(ps_merged_agg).mark_line().encode(\n",
        "    x=alt.X('year:O', title='Year'),\n",
        "    y=alt.Y('sale_price_mean:Q', \n",
        "            title='Average Sale Price By Year',\n",
        "            axis=alt.Axis(format='.1f')),\n",
        "    tooltip=[alt.Tooltip('year:O', title='Year'),\n",
        "             alt.Tooltip('sale_price_mean:Q', \n",
        "             format='.2f', title='Average Sale Price')]\n",
        ").properties(\n",
        "    title=\"Average Sale Price Over Time\",\n",
        "    width=300,\n",
        "    height=200\n",
        ")\n",
        "\n",
        "line_chart"
      ],
      "id": "66a879b0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "venv",
      "language": "python",
      "display_name": "Python (venv)",
      "path": "/Users/sarahkim/Library/Jupyter/kernels/venv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}